{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 문제 유형별 MLP 네트워크\n",
    "- MLP(Multi Layer Perceptron), ANN(Artificial Neural Network), DNN (Deep Neural Network)\n",
    "    - Fully Connected Layer(Dense)로 구성된 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Regression(회귀)\n",
    "\n",
    "## Boston Housing Dataset\n",
    "보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제.\n",
    "- CRIM: 범죄율\n",
    "- ZN: 25,000 평방피트당 주거지역 비율\n",
    "- INDUS: 비소매 상업지구 비율\n",
    "- CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n",
    "- NOX: 일산화질소 농도(단위: 0.1ppm)\n",
    "- RM: 주택당 방의 수\n",
    "- AGE: 1940년 이전에 건설된 주택의 비율\n",
    "- DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n",
    "- RAD: 고속도로 접근성\n",
    "- TAX: 재산세율\n",
    "- PTRATIO: 학생/교사 비율\n",
    "- B: 흑인 비율\n",
    "- LSTAT: 하위 계층 비율\n",
    "<br><br>\n",
    "- **Target**\n",
    "    - MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed값 설정\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, y_train), (test_X, y_test) = keras.datasets.boston_housing.load_data()\n",
    "print(train_X.shape, y_train.shape)\n",
    "print(test_X.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 하이퍼파라미터, 변수 정의\n",
    "- 하이퍼파라미터와 중복되서 사용할 변수들을 미리 모아서 정의하면 관리하기 편리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼파라미터 변수\n",
    "\n",
    "# 학습율 => 파라미터 업데이트시 계산된 gradient를 파라미터에 적용할 비율. 0 ~ 1 사이 실수를 지정한다. optimizer 생성때 설정.\n",
    "LEARNING_RATE = 0.001  \n",
    "N_EPOCH = 100 # 에폭수\n",
    "N_BATCH = 200 # Train 배치사이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### X, y 전처리\n",
    "- MLP는 선형모델을 기반으로 하므로 Feature scaling을 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_X)\n",
    "X_test = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델 구현\n",
    "\n",
    "1. 모델 객체 생성 - Sequential\n",
    "2. 모델에 Layer들 추가\n",
    "    - Input Layer 추가\n",
    "        - 입력 데이터의 shape을 지정한다.\n",
    "        1. InputLayer 객체를 생성해서 추가한다.\n",
    "        2. 첫번째 Hidden Layer에 input_shape 매개변수에 shape을 지정하여 추가한다.\n",
    "    - Hidden Layer들 추가\n",
    "        - Layer의 개수와 Layer의 Unit의 개수는 튜닝대상으로 성능에 영향을 준다.\n",
    "        - 활성함수는 ReLU 를 사용한다.\n",
    "        - Layer의 개수와 Unit 개수가 많을 수록 복잡한 모델, 적을 수록 단순한 모델이된다.\n",
    "    - Output Layer 추가\n",
    "        - 풀려는 문제에 따라 unit개수와 활성함수를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_boston(lr=0.01):\n",
    "    model = keras.Sequential()\n",
    "   \n",
    "    model.add(layers.Dense(units=32, activation='relu', input_shape=(13, )))\n",
    "    model.add(layers.Dense(units=16, activation='relu'))\n",
    "    model.add(layers.Dense(units=8, activation='relu'))\n",
    "    \n",
    "\n",
    "    # 집값 한개의 값을 추론하므로 unit수를 1로 지정. \n",
    "    model.add(layers.Dense(units=1))\n",
    "    \n",
    "    # 컴파일\n",
    "    # optimizer를 파라미터값들을 모두 default로 설정해서 생성할 경우 문자열로 지정. (\"adam\")    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_boston = get_model_boston()\n",
    "\n",
    "# 딥러닝 모델의 구조 확인\n",
    "model_boston.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model_boston, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 학습(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model_boston.fit(X_train, \n",
    "                        y_train,\n",
    "                        epochs=N_EPOCH, \n",
    "                        batch_size=N_BATCH,\n",
    "                        validation_split=0.2\n",
    "                        \n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 결과 시각화\n",
    "- 학습 시 epoch별 검증 결과를 시각화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist.history : 에폭별 검증 결과\n",
    "# hist.epoch : 에폭리스트\n",
    "plt.plot(hist.epoch, hist.history['loss'], label='Train set')\n",
    "plt.plot(hist.epoch, hist.history['val_loss'], label='Validation set')\n",
    "\n",
    "plt.title('Loss')\n",
    "# plt.ylim(0, 30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 최종 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_boston.evaluate(X_test, y_test)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델 네트워크 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#### 전체 경로 안에 한글이 있으면 안된다.\n",
    "saved_dir = 'saved_model/boston_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_boston.save(saved_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델을 불러와서 추론\n",
    "saved_model = keras.models.load_model(saved_dir)\n",
    "saved_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:5]\n",
    "pred = saved_model.predict(X_new)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 분류 (Classification)\n",
    "\n",
    "## Fashion MNIST Dataset - 다중분류(Multi-Class Classification) 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋. \n",
    "이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 의류 품목을 나타낸다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>그림</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "이미지는 28x28 크기이며 Gray scale이다. *레이블*(label)은 0에서 9까지의 정수 배열이다. 아래 표는 이미지에 있는 의류의 **클래스**(class)들이다.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>class index</th>\n",
    "    <th>class name</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trousers</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "각 이미지는 하나의 레이블에 매핑되어 있다. 데이터셋에 클래스 이름이 들어있지 않기 때문에 나중에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# seed 값 설정\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class_names = np.array(['T-shirt/top', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Data 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, y_train), (test_image, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "train_image.shape, y_train.shape, test_image.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### validatation dataset set  분리\n",
    "- Train set을 Train/validation set으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 25  # 확인할 이미지개수 (5배수)\n",
    "plt.figure(figsize=(7,7))\n",
    "for i in range(cnt):\n",
    "    plt.subplot(5, int(cnt/5), i+1)\n",
    "    plt.imshow(train_image[i], cmap='Greys')  # gray: 0-black, 255: white,  Greys: 0-white, 255-black\n",
    "    label = class_names[y_train[i]]\n",
    "    plt.title(label)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 하이퍼파라미터, 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001  # 학습률\n",
    "N_EPOCH = 20          # 에폭수\n",
    "N_BATCH = 1000         # 배치 사이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### X, y  전처리\n",
    "- y값 처리\n",
    "    1. 다중 분류에서 label encoding 형식의 label을 one hot encoding 처리 ==> loss: categorical_crossentropy\n",
    "    2. label encoding 형식의 label을 그대로 모델에 전달. => loss: sparse_categorical_crossentropy\n",
    "        - one hot encoding 처리를 loss가 대신 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- x값(이미지) 처리\n",
    "    - dtype을 uint8에서 float32로 변환한다.\n",
    "    - 0 ~ 1 정규화. X/255.0으로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_image.astype('float32')/255.0\n",
    "X_test = test_image.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_image.min(), train_image.max())\n",
    "print(X_train.min(), X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델 생성 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_fashion(lr=0.01):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    \n",
    "    # Dense Layer의 Unit개수는 점점 줄여나가는 패턴을 사용.\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    \n",
    "    # output layer\n",
    "    ## class 별 확률을 출력해야하므로 activation은 softmax를 사용하고 fashion mnist class개수인 10을 unit개수로 지정한다.\n",
    "    model.add(layers.Dense(10, activation='softmax', name='output'))\n",
    "    \n",
    "    # 컴파일\n",
    "    # 다중분류 loss함수:\n",
    "    #   y가 one hot encoding이 안된 경우: sparse_categorical_crossentropy  (원핫인코딩 후 loss를 계산한다.)\n",
    "    #   y를 one hot encoding 한 경우: categorical_crossentropy\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr), \n",
    "                  loss='sparse_categorical_crossentropy',   \n",
    "                  metrics=['accuracy']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fashion = get_model_fashion(LEARNING_RATE)\n",
    "model_fashion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model_fashion, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Train(학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model_fashion.fit(X_train, y_train, epochs=N_EPOCH, batch_size=N_BATCH, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 결과 시각화\n",
    "- 학습 시 epoch별 검증 결과를 시각화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.epoch, hist.history['loss'], label=\"train\")\n",
    "plt.plot(hist.epoch, hist.history['val_loss'], label='validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.epoch, hist.history['accuracy'], label='train')\n",
    "plt.plot(hist.epoch, hist.history['val_accuracy'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 최종평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model_fashion.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"테스트결과: Loss: {loss}, 정확도: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_fashion = 'saved_model/fashion_mnist_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fashion.save(save_dir_fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델을 loading해서 추론\n",
    "saved_model_fashion = keras.models.load_model(save_dir_fashion)\n",
    "saved_model_fashion.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X_test[1000:1010]\n",
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = saved_model_fashion.predict(new_X)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 추론결과에 대한 후처리 작업\n",
    "## class, class name 조회\n",
    "label = np.argmax(pred, axis=-1)\n",
    "label_name = class_names[label]\n",
    "## 확률 조회\n",
    "proba = np.max(pred, axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (n, p) in enumerate(zip(label_name, proba), start=1):\n",
    "    print(f\"{idx}. {n} - {int(p*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답과 비교\n",
    "class_names[y_test[1000:1010]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 위스콘신 유방암 데이터셋 - 이진분류(Binary Classification) 문제\n",
    "\n",
    "- **이진 분류 문제 처리 모델의 두가지 방법**\n",
    "    1. positive(1)일 확률을 출력하도록 구현\n",
    "        - output layer: units=1, activation='sigmoid'\n",
    "        - loss: binary_crossentropy\n",
    "    2. negative(0)일 확률과 positive(1)일 확률을 출력하도록 구현 => 다중분류 처리 방식으로 해결\n",
    "        - output layer: units=2, activation='softmax', y(정답)은 one hot encoding 처리\n",
    "        - loss: categorical_crossentropy\n",
    "        \n",
    "- 위스콘신 대학교에서 제공한 종양의 악성/양성여부 분류를 위한 데이터셋\n",
    "- Feature\n",
    "    - 종양에 대한 다양한 측정값들\n",
    "- Target의 class\n",
    "    - 0 - malignant(악성종양)\n",
    "    - 1 - benign(양성종양)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 데이터 로딩, train/validation/test set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "# Train / Validation 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 하이퍼파라미터, 변수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "N_EPOCH = 50\n",
    "N_BATCH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 데이터 전처리\n",
    "- y (label) 처리\n",
    "    - 이진 분류\n",
    "        - 양성의 확률을 출력하도록 모델을 구성하는 경우 그대로 사용.\n",
    "        - 양성일 확률, 음성일 확률을 출력하도록 모델을 구성하는 경우(다중분류 방식으로 처리) one hot encoding 처리한다.\n",
    "- X (feature) 처리\n",
    "    - 문자열(범주형): one hot encoding\n",
    "    - 연속형(수치형): feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### model 생성, 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "\n",
    "def get_model_cancer(lr=0.01):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    #Hidden layer\n",
    "    model.add(layers.Dense(32, activation='relu', input_shape=(30,)))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    \n",
    "    # Output Layer\n",
    "    # 이진분류(양성일 확률을 출력):\n",
    "    ##  unit개수-1개(positive-양성일 확률), activation: \"sigmoid(logistic)\"\n",
    "    model.add(layers.Dense(1, activation='sigmoid', name='output_layer'))\n",
    "    \n",
    "    # 컴파일 - 이진분류의 loss함수: binary_crossentropy\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', Recall(), Precision()])  # Recall, Precision은 문자열을 지원안하므로 직접 객체생성한다.\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cancer = get_model_cancer(LEARNING_RATE)\n",
    "model_cancer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model_cancer, show_shapes=True, to_file='model_cancer.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Train(학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_cancer.fit(X_train_scaled, y_train, epochs=N_EPOCH, batch_size=N_BATCH, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.epoch, hist.history['loss'], label=\"train\")\n",
    "plt.plot(hist.epoch, hist.history['val_loss'], label='validation')\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.epoch, hist.history['accuracy'], label='train')\n",
    "plt.plot(hist.epoch, hist.history['val_accuracy'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 최종평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, recall, precision = model_cancer.evaluate(X_test_scaled, y_test)\n",
    "print(loss, acc, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_path = 'saved_model/cancer_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cancer.save(save_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = models.load_model(save_dir_path)\n",
    "saved_model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X_test_scaled[:10]\n",
    "pred = saved_model.predict(new_X)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델출력결과 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pred >= 0.5, '양성- 1', '악성- 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_test[:10] == 1, \"양성\", \"악성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
